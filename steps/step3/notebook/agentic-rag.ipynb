{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "id": "e443985d-0186-4fc6-8139-886f48b2b237"
   },
   "outputs": [],
   "source": [
    "## TODO UPDATE THE ID BEFORE RUNING THE NOTEBOOK\n",
    "## If you are unsure how to collect the different ID, please ask your instructor\n",
    "\n",
    "# Your IBM Cloud API Key, required to authenticate yourself when accessing the services using the python SDK\n",
    "CLOUD_API_KEY = \"*************************\"\n",
    "\n",
    "# Your ModelManagement/OpenScale Instance ID that has been provisionned for you\n",
    "OPENSCALE_INSTANCE_ID = \"*************************\" # Update this to refer to a particular service instance\n",
    "\n",
    "# The watsonx.ai project, this is required to store artefacts inside the studio so you can proceed with lab\n",
    "PROJECT_ID = \"*************************\"\n",
    "\n",
    "# The unique name of the watsonx.ai Agentic RAG Langchain Developement like \"Agentic RAG using LangChain\"\n",
    "AGENTIC_RAG_LC_DEV_NAME = \"*************************\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "id": "f2568167-18c4-4a70-894b-52634073ee03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson-openscale) (3.7)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (4.15.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from importlib-metadata->ibm_watson_machine_learning) (3.20.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas->ibm-aigov-facts-client) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ibm-watson-openscale | tail -n 1\n",
    "!pip install --upgrade ibm-watsonx-ai | tail -n 1\n",
    "!pip install langchain | tail -n 1\n",
    "!pip install langchain-ibm | tail -n 1\n",
    "!pip install langchain-community | tail -n 1\n",
    "!pip install ibm_watson_machine_learning | tail -n 1\n",
    "!pip install chromadb | tail -n 1\n",
    "!pip install tiktoken | tail -n 1\n",
    "!pip install --upgrade ibm-aigov-facts-client | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43c19b29-f106-4111-ae53-f4c728a3ecb1"
   },
   "source": [
    "# Evaluating Answer Quality and Retrieval Quality of Agentic RAG system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39dc54d3-5342-4cd9-8379-f3983dbbdf50"
   },
   "source": [
    "This notebook demonstrates the following:\n",
    "\n",
    "* Create an Agent with two tools.\n",
    "* One tool is, for a given question, retrieve the context from EU AI Act summary document from https://artificialintelligenceact.eu/high-level-summary/\n",
    "* Another tool is, for a given question, retrieve the context from HR FAQs.\n",
    "* Against the Agent, run couple of questions related to EU AI Act and HR FAQs using the system prompt and human prompt as described in the notebook.\n",
    "* As part of this process, collect the following details - question, context from either EU AI Act related tool or from FAQ related tool, and the respective answers.\n",
    "* Then, create a Detached Prompt Template using the combination of the system prompt + human prompt.\n",
    "* Use Mistral model as the RAG LLM-as-a-Judge evaluator for evaluating RAG metrics.\n",
    "* Log and evaluate the metrics.\n",
    "* And visualise the metrics via., watsonx.governance UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b22fc40-45d6-4557-8039-6e8536c8dfb8"
   },
   "source": [
    "## Imports <a name=\"Necessary Imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "id": "ffdf8565-db6f-4492-9cd0-55e40723b79f"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "from langchain_ibm import WatsonxEmbeddings, WatsonxLLM\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1c1166f-6bcb-4009-aaf0-89e12e236add"
   },
   "source": [
    "### Configure your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "id": "d17f26b6-ccca-4714-8576-2308f23bf9a3"
   },
   "outputs": [],
   "source": [
    "IAM_URL = \"https://iam.cloud.ibm.com\"\n",
    "DATAPLATFORM_URL = \"https://api.dataplatform.cloud.ibm.com\"\n",
    "FACTSHEET_URL = \"https://dataplatform.cloud.ibm.com\"\n",
    "SERVICE_URL = \"https://aiopenscale.cloud.ibm.com\"\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": CLOUD_API_KEY,\n",
    "}\n",
    "CREDENTIALS = credentials\n",
    "project_id = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebe098e3-5f3d-424d-8a4f-f4d95827280f"
   },
   "source": [
    "## watsonx LLM for Prompt Generation <a name=\"Prompt Generation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "id": "6d329d81-442d-47cb-9a65-5bed5a44132e"
   },
   "outputs": [],
   "source": [
    "llm = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-3-3-8b-instruct\", \n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params={\n",
    "        GenParams.DECODING_METHOD: \"greedy\",\n",
    "        GenParams.TEMPERATURE: 0,\n",
    "        GenParams.MIN_NEW_TOKENS: 5,\n",
    "        GenParams.MAX_NEW_TOKENS: 250,\n",
    "        GenParams.STOP_SEQUENCES: [\"Human:\", \"Observation\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f48349a8-ff7e-4120-938d-c36e66f6dacb"
   },
   "source": [
    "## Slate Model for Embeddings Generation <a name=\"Embeddings Generation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "id": "51f72c5a-7d99-4a0e-9195-582b778772fc"
   },
   "outputs": [],
   "source": [
    "# slate-30m-english-rtrvr-v2\n",
    "def get_embeddings():\n",
    "    embeddings = WatsonxEmbeddings(\n",
    "        model_id=\"ibm/slate-30m-english-rtrvr-v2\", #    EmbeddingTypes.IBM_SLATE_30M_ENG.value,\n",
    "        url=credentials[\"url\"],\n",
    "        apikey=credentials[\"apikey\"],\n",
    "        project_id=project_id,\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "id": "c6dec697-f979-46d5-a431-ea935473304f"
   },
   "outputs": [],
   "source": [
    "def get_text_splitter():\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=250, chunk_overlap=0\n",
    "    )\n",
    "    return text_splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63aa308a-a92a-4721-bd2d-2738c95561b3"
   },
   "source": [
    "## Doc URLS <a name=\"Doc URLS\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "id": "29931b66-efcc-4fa4-8830-9e1e39c978e8"
   },
   "outputs": [],
   "source": [
    "hr_faq_urls = [\n",
    "    'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'\n",
    "]\n",
    "\n",
    "ai_act_urls = [\n",
    "    'https://artificialintelligenceact.eu/high-level-summary/'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed0576d0-090c-423c-ae54-58094171ea4b"
   },
   "source": [
    "## Vector Store Retriever against a given doc source<a name=\"Vector Store Retriever\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "id": "1ca5cc5f-f338-4518-8533-484e0281c1f6"
   },
   "outputs": [],
   "source": [
    "def get_retriever(urls, collection_name):\n",
    "    docs = [WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    text_splitter = get_text_splitter()\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_splits,\n",
    "        collection_name=collection_name,\n",
    "        embedding=get_embeddings(),\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c92c511-5573-4572-9f5c-bf30d249b8d3"
   },
   "source": [
    "## Retriever for FAQs document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "id": "0ec06b60-09c0-494e-ac92-d4bacfb61561"
   },
   "outputs": [],
   "source": [
    "hr_faqs_retriever = get_retriever(urls=hr_faq_urls, collection_name='hr_faqs')\n",
    "ai_act_retriever = get_retriever(urls=ai_act_urls, collection_name='ai_act')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b2db67a-de70-4752-8b2c-ae3ba68d115a"
   },
   "source": [
    "## Agentic AI tools. One wrapping the FAQs and other wrapping the EU AI Act summary document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "id": "488f9484-1dfe-49a3-820c-30fc0a3b2565"
   },
   "outputs": [],
   "source": [
    "\n",
    "hr_faqs_context = \"\"\n",
    "ai_act_context = \"\"\n",
    "\n",
    "@tool\n",
    "def get_HR_FAQs_Context(question: str):\n",
    "    \"\"\"Get context from Hr documents related Frequently asked questions.\"\"\"\n",
    "    global hr_faqs_context\n",
    "    hr_faqs_context = hr_faqs_retriever.invoke(question)\n",
    "    return hr_faqs_context\n",
    "\n",
    "@tool\n",
    "def get_AI_Act_Summary_Context(question: str):\n",
    "    \"\"\"Get context from High-level summary of the AI Act.\"\"\"\n",
    "    global ai_act_context\n",
    "    ai_act_context = ai_act_retriever.invoke(question)\n",
    "    return ai_act_context\n",
    "\n",
    "tools = [get_HR_FAQs_Context]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb342e57-55f5-41d8-83dd-92fb78d8b4ef"
   },
   "source": [
    "## Standard Langchain based System Prompt working as an Generative AI Agent\n",
    "\n",
    "Next, we will set up a new prompt template to ask multiple questions. This template is more complex. It is referred to as a [structured chat prompt](https://api.python.langchain.com/en/latest/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html#langchain-agents-structured-chat-base-create-structured-chat-agent) and can be used for creating agents that have multiple tools available. In our case, the tool we are using was defined in Step 6. The structured chat prompt will be made up of a `system_prompt`, a `human_prompt` and our RAG tool. \n",
    "\n",
    "First, we will set up the `system_prompt`. This prompt instructs the agent to print its \"thought process,\" which involves the agent's subtasks, the tools that were used and the final output. This gives us insight into the agent's function calling. The prompt also instructs the agent to return its responses in JSON Blob format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "id": "ec330646-2c8c-424d-9e2c-6eb5a0308cf8"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools: {tools}\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\"\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "Follow this format:\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "Begin! Reminder to ALWAYS respond with a valid json blob of a single action.\n",
    "Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ce799d3-146f-457f-8542-9af7d54bd768"
   },
   "source": [
    "## The human prompt\n",
    "\n",
    "In the following code, we are establishing the `human_prompt`. This prompt tells the agent to display the user input followed by the intermediate steps taken by the agent as part of the `agent_scratchpad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "id": "7c29eed5-219b-4b0a-aead-787da37d1cd5"
   },
   "outputs": [],
   "source": [
    "human_prompt = \"\"\"{input}\n",
    "{agent_scratchpad}\n",
    "(reminder to always respond in a JSON blob)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d023856-69b4-40f2-8970-313fc846037f"
   },
   "source": [
    "Next, we establish the order of our newly defined prompts in the prompt template. We create this new template to feature the `system_prompt` followed by an optional list of messages collected in the agent's memory, if any, and finally, the `human_prompt` which includes both the human input and `agent_scratchpad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "id": "1ddd3aa3-df2b-4a7b-9ee3-22b308628373"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "267a90df-211b-48a0-a77d-7b87bcbbc8bb"
   },
   "source": [
    "Now, let's finalize our prompt template by adding the tool names, descriptions and arguments using a [partial prompt template](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/partial/). This allows the agent to access the information pertaining to each tool including the intended use cases and also means we can add and remove tools without altering our entire prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "id": "507e24be-78a9-46c3-b4c3-0ece533c36fb"
   },
   "outputs": [],
   "source": [
    "prompt = prompt.partial(\n",
    "    tools=render_text_description_and_args(list(tools)),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ad9f708-7de3-4d1a-b7d1-217d0a072b2e"
   },
   "source": [
    "## Set up the agent's memory and chain\n",
    "\n",
    "An important feature of AI agents is their memory. Agents are able to store past conversations and past findings in their memory to improve the accuracy and relevance of their responses going forward. In our case, we will use LangChain's `ConversationBufferMemory()` as a means of memory storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13b1eae8-f20c-4cd6-9d2c-83ff8d540dd3"
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "id": "b3fa682a-a44f-461c-8e41-8a47d937c3ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respond to the human as helpfully and accurately as possible. You have access to the following tools: {tools}\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\"\n",
      "```\n",
      "{{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}}\n",
      "```\n",
      "Follow this format:\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}}\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action.\n",
      "Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n",
      "\n",
      "{input}\n",
      "{agent_scratchpad}\n",
      "(reminder to always respond in a JSON blob)\n"
     ]
    }
   ],
   "source": [
    "prompt_input = prompt.messages[0].prompt.template + '\\n\\n' + prompt.messages[2].prompt.template\n",
    "print(prompt_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03fb4493-8a41-4b85-8d45-c4f5a369ebd2"
   },
   "source": [
    "And now we can set up a chain with our agent's scratchpad, memory, prompt and the LLM. The AgentExecutor class is used to execute the agent. It takes the agent, its tools, error handling approach, verbose parameter and memory as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "943aa7cb-cc68-4424-ba3e-68257cd43a44"
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        chat_history=lambda x: memory.chat_memory.messages,\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=chain, tools=tools, handle_parsing_errors=True, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07acd16c-b406-437e-af8d-48746d75585e"
   },
   "source": [
    "## Utility method to construct the context as retrieved from respective vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "id": "03be8021-6e1a-4cda-8ddb-7db7c4266766"
   },
   "outputs": [],
   "source": [
    "def construct_context(relevant_context):\n",
    "    context_str = ''\n",
    "    for doc in relevant_context:\n",
    "        context_str = context_str + doc.page_content + '\\n\\n'\n",
    "    return context_str    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "id": "3f832cbc-a365-4f31-8461-7ccbb640edf9"
   },
   "outputs": [],
   "source": [
    "# Store the complete the context\n",
    "complete_content = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a919b009-2a7c-4bd5-96cc-f2ec8009073d"
   },
   "source": [
    "## Generate responses with the agentic RAG system\n",
    "\n",
    "We are now able to ask the agent questions. Recall the agent's previous inability to provide us with information pertaining to the 2024 US Open. Now that the agent has its RAG tool available to use, let's try asking the same questions again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "908321ac-7b7c-4a0e-8f10-ffa73d06cb53"
   },
   "source": [
    "### Question 1. Related to FAQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "id": "438803ec-5071-40cd-9763-80c0cd0add11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Thought: The user is asking about discrimination in the workplace. I should use the get_HR_FAQs_Context tool to provide a detailed answer.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_HR_FAQs_Context\",\n",
      "  \"action_input\": \"discrimination in the workplace\"\n",
      "}\n",
      "```\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m[Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content=\"We prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\"), Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content=\"We prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\"), Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content=\"We prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\"), Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content=\"We prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\")]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The company prohibits discrimination and harassment in the workplace based on various factors such as race, color, national origin, ancestry, ethnic origin, citizenship status, creed, religion, religious affiliation, religious views, age, sex, gender, pregnancy, maternity, paternity, caring responsibilities, marital status, relationship status, civil partnership, sexual orientation, transgender status, gender identity, gender expression, intersex status, genetic information, physical or mental disability, protected condition, military or veteran status, domestic violence, sexual assault or abuse, being a victim of a crime, and any other community group protected under applicable law or local law. Always conduct yourself appropriately when acting on behalf of the firm, both inside and outside the office, as your conduct reflects the firm's standards.\"\n",
      "}\n",
      "```\n",
      "Observation\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"discrimination in the workplace?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa2f6c4a-5c41-44bc-bc73-a7c3e2d1f255"
   },
   "source": [
    "## Capture the output for logging with watsonx.governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "id": "374d0614-392a-4d75-b1d3-89697626b5e3"
   },
   "outputs": [],
   "source": [
    "prompt_result = {}\n",
    "prompt_result['query'] = response['input']\n",
    "prompt_result['context'] = construct_context(hr_faqs_context)\n",
    "prompt_result['generated_text'] = response['output']\n",
    "complete_content.append(prompt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "id": "0a57815c-ec5e-4ed7-87b0-2c89d3064b83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'discrimination in the workplace?',\n",
       "  'context': \"We prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\\n\\nWe prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\\n\\nWe prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\\n\\nWe prohibit discrimination, harassment, bias and prejudice in our\\nworkplace and against our workforce based on an individual’s race, color,\\nnational origin or ancestry, ethnic origin, citizenship status, creed, religion,\\nreligious affiliation, religious views, age, sex, gender, pregnancy, maternity,\\npaternity, caring responsibilities, marital status, relationship status, civil\\npartnership, sexual orientation, transgender status, gender identity,\\ngender expression, intersex status, genetic information, physical or mental\\ndisability or protected condition, military or veteran status, an individual\\nhaving been a victim of domestic violence, sexual assault or abuse, an\\nindividual being the victim of a crime, any other community group\\nprotected under applicable law, or any other status protected under\\napplicable local law.\\n\\nAlways conduct yourself appropriately when acting on behalf of our firm\\n— both inside and outside of the office. Your conduct matters and can be\\nperceived as a reflection of our firm's standards.\\n\\n\",\n",
       "  'generated_text': \"The company prohibits discrimination and harassment in the workplace based on various factors such as race, color, national origin, ancestry, ethnic origin, citizenship status, creed, religion, religious affiliation, religious views, age, sex, gender, pregnancy, maternity, paternity, caring responsibilities, marital status, relationship status, civil partnership, sexual orientation, transgender status, gender identity, gender expression, intersex status, genetic information, physical or mental disability, protected condition, military or veteran status, domestic violence, sexual assault or abuse, being a victim of a crime, and any other community group protected under applicable law or local law. Always conduct yourself appropriately when acting on behalf of the firm, both inside and outside the office, as your conduct reflects the firm's standards.\"}]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1939f20-58b5-48bf-bec8-a3cf4db49250"
   },
   "source": [
    "### Question 2. Related to work/life balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "id": "0fa52925-d372-49fb-9db1-d0de8788e0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Thought: The user is asking about compliance with law and firm policies in HR processes. I can use the get_HR_FAQs_Context tool to find relevant information.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_HR_FAQs_Context\",\n",
      "  \"action_input\": \"compliance with law and firm policies for HR processes\"\n",
      "}\n",
      "```\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m[Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content='If you have questions about the Code of Conduct or any firm policy, ask your\\nmanager, Human Resources, or local Compliance Officer for guidance.\\nOur continued success is based on your commitment to do the right thing.'), Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content='If you have questions about the Code of Conduct or any firm policy, ask your\\nmanager, Human Resources, or local Compliance Officer for guidance.\\nOur continued success is based on your commitment to do the right thing.'), Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content='If you have questions about the Code of Conduct or any firm policy, ask your\\nmanager, Human Resources, or local Compliance Officer for guidance.\\nOur continued success is based on your commitment to do the right thing.'), Document(metadata={'source': 'https://raw.githubusercontent.com/jpradier/watsonx-orchestrate-developer-toolkit/refs/heads/main/code-of-conduct.txt'}, page_content='If you have questions about the Code of Conduct or any firm policy, ask your\\nmanager, Human Resources, or local Compliance Officer for guidance.\\nOur continued success is based on your commitment to do the right thing.')]\u001b[0m\u001b[32;1m\u001b[1;3m The context from the HR FAQs indicates that for specific policy inquiries, including compliance with law and firm policies in HR processes, the user should consult their manager, Human Resources, or local Compliance Officer for guidance.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Compliance with law and firm policies for HR processes involves adhering to legal requirements and internal regulations set by the company. If you have questions about specific policies, it's recommended to consult your manager, Human Resources, or local Compliance Officer for guidance.\"\n",
      "}\n",
      "```\n",
      "Observation\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What is compliance with law and firm policies for HR process?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "id": "f58754cb-f602-4d1d-aadb-67593bdeb9fd"
   },
   "outputs": [],
   "source": [
    "prompt_result = {}\n",
    "prompt_result['query'] = response['input']\n",
    "prompt_result['context'] = construct_context(hr_faqs_context)\n",
    "prompt_result['generated_text'] = response['output']\n",
    "complete_content.append(prompt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "id": "b14d579a-4fea-4ef0-af81-f00bec6ea0a0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "llm_data = pd.DataFrame(complete_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "id": "16a119f4-7bf9-485c-be6e-823d9530152c"
   },
   "outputs": [],
   "source": [
    "llm_data['reference'] = llm_data['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "id": "35735ae0-d03b-41cd-97f6-e04c6ee39fdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discrimination in the workplace?</td>\n",
       "      <td>We prohibit discrimination, harassment, bias a...</td>\n",
       "      <td>The company prohibits discrimination and haras...</td>\n",
       "      <td>The company prohibits discrimination and haras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is compliance with law and firm policies ...</td>\n",
       "      <td>If you have questions about the Code of Conduc...</td>\n",
       "      <td>Compliance with law and firm policies for HR p...</td>\n",
       "      <td>Compliance with law and firm policies for HR p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                   discrimination in the workplace?   \n",
       "1  What is compliance with law and firm policies ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  We prohibit discrimination, harassment, bias a...   \n",
       "1  If you have questions about the Code of Conduc...   \n",
       "\n",
       "                                      generated_text  \\\n",
       "0  The company prohibits discrimination and haras...   \n",
       "1  Compliance with law and firm policies for HR p...   \n",
       "\n",
       "                                           reference  \n",
       "0  The company prohibits discrimination and haras...  \n",
       "1  Compliance with law and firm policies for HR p...  "
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6515fa07-5b1a-4a53-82c5-e34266b4fc21"
   },
   "source": [
    "# Computing Answer Quality and Retrieval Quality Metrics using IBM watsonx.governance for RAG task\n",
    "\n",
    "This notebook demonstrates the creation of a Retrieval Augumented Generation (RAG) pattern using watsonx.ai and computations of reference-free Answer Quality metrics, such as **Faithfulness**, **Answer relevance**, **Unsuccessful requests**, Content Analysis metrics such as **Coverage**, **Density**, **Abstractness** and Retrieval Quality Metrics such as **Context Relevance**, **Retrieval Precision**, **Average Precision**, **Reciprocal Rank**, **Hit Rate** and **Normalized Discounted Cumulative Gain** for the RAG task type. It also identifies the source attribution using watsonx.governance.\n",
    "\n",
    "- **Faithfulness** measures how faithful the model output or generated text is to the context sent to the LLM input. The faithfulness score is a value between 0 and 1. A value closer to 1 indicates that the output is more faithful - or grounded - and less hallucinated. A value closer to 0 indicates that the output is less faithful and more hallucinated.\n",
    "\n",
    "- **Answer relevance** measures how relevant the answer or generated text is to the question. This is one of the ways to determine the quality of your model. The answer relevance score is a value between 0 and 1. A value closer to 1 indicates that the answer is more relevant to the given question. A value closer to 0 indicates that the answer is less relevant to the question.\n",
    "\n",
    "- **Unsuccessful requests** measures the ratio of questions answered unsuccessfully out of the total number of questions. The unsuccessful requests score is a value between 0 and 1. A value closer to 0 indicates that the model is successfully answering the questions. A value closer to 1 indicates the model is not able to answer the questions.\n",
    "\n",
    "- **Coverage** metric quantifies the extent to which the model output. It measures the percentage of output words that are also in the input text. The coverage score is a value between 0 and 1. A higher score close to 1 indicates that higher percentage of output words are within the input text.\n",
    "\n",
    "- **Density** quantifies how well the summary or the answer in the model output can be described as a series of extractions from the model input or context. A lower value of density metric indicates that on average the extractive fragments do not closely resemble verbatim extractions from the original source or context text. Abstractive summarization involves generating new, concise sentences that convey the main ideas of the source text but may not be directly copied from it. This is in contrast to extractive summarization, where the summary consists mainly of sentences directly lifted from the source. The lower the score the more abstractive the model output is.\n",
    "\n",
    "- **Abstractness** measures the abstractness of the model generated text by measuring the new n-grams generated in the model output compared to the model input. The metric computes the ratio of n-grams in the generated text that do not appear in the source content or context send to the model. The abstractness score is a value between 0 and 1. A higher score close to 1 indicates high abstractness in the generated text.\n",
    "\n",
    "- **Context Relevance** assesses the degree to which the retrieved context is relevant to the question sent to the LLM. This is one of the ways to determine the quality of your retrieval system. The context relevance score is a value between 0 and 1. A value closer to 1 indicates that the context is more relevant to your question in the prompt. A value closer to 0 indicates that the context is less relevant to your question in the prompt.\n",
    "\n",
    "- **Retrieval Precision** measures the quantity of relevant contexts from the total contexts retrieved. The retrieval precision is a value between 0 and 1. A value of 1 indicates that all the retrieved contexts are relevant. A value of 0 indicates that none of the retrieved contexts are relevant.\n",
    "\n",
    "- **Average Precision** evaluates whether all the relevant contexts are ranked higher or not. It is the mean of the precision scores of relevant contexts. The average precision is a value between 0 and 1. A value of 1 indicates that all the relevant contexts are ranked higher. A value of 0 indicates that none of the retrieved contexts are relevant.\n",
    "\n",
    "- **Reciprocal Rank** is the reciprocal of the rank of the first relevant context. The retrieval reciprocal rank is a value between 0 and 1. A value of 1 indicates that the first relevant context is at first position. A value of 0 indicates that none of the relevant contexts are retrieved.\n",
    "\n",
    "- **Hit Rate** Hit Rate measures whether there is atleast one relevant context among the retrieved contexts. The hit rate value is either 0 or 1. A value of 1 indicates that there is at least one relevant context. A value of 0 indicates that there is no relevant context in the retrieved contexts.\n",
    "\n",
    "- **Normalized Discounted Cumulative Gain** Normalized Discounted Cumulative Gain or NDCG measures the ranking quality of the retrieved contexts. The ndcg is a value between 0 and 1. A value of 1 indicates that the retrieved contexts are ranked in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "id": "8077b3d9-a583-4814-9cfb-27ac1bdbc04b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.7'"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "wml_client = APIClient(credentials)\n",
    "wml_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3bebb68-8c3c-46f3-8c30-c6926fde5d0d"
   },
   "source": [
    "### Function to create the access token\n",
    "This function generates an IAM access token using the provided credentials. The API calls for creating and scoring prompt template assets utilize the token generated by this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "id": "1c33e5ab-54fe-40b7-b0b9-f81f17925c6c"
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "def generate_access_token():\n",
    "    headers={}\n",
    "    headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "    data = {\n",
    "        \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "        \"apikey\": CLOUD_API_KEY,\n",
    "        \"response_type\": \"cloud_iam\"\n",
    "    }\n",
    "    response = requests.post(IAM_URL + \"/identity/token\", data=data, headers=headers)\n",
    "    json_data = response.json()\n",
    "    iam_access_token = json_data[\"access_token\"]\n",
    "        \n",
    "    return iam_access_token\n",
    "\n",
    "iam_access_token = generate_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "id": "898372f6-0411-486d-82ac-461c2a817981"
   },
   "outputs": [],
   "source": [
    "test_data_path = \"RAG_data.csv\"\n",
    "llm_data.to_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "id": "1973ea78-aa07-467c-9abc-faf32ce41394"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discrimination in the workplace?</td>\n",
       "      <td>We prohibit discrimination, harassment, bias a...</td>\n",
       "      <td>The company prohibits discrimination and haras...</td>\n",
       "      <td>The company prohibits discrimination and haras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is compliance with law and firm policies ...</td>\n",
       "      <td>If you have questions about the Code of Conduc...</td>\n",
       "      <td>Compliance with law and firm policies for HR p...</td>\n",
       "      <td>Compliance with law and firm policies for HR p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                   discrimination in the workplace?   \n",
       "1  What is compliance with law and firm policies ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  We prohibit discrimination, harassment, bias a...   \n",
       "1  If you have questions about the Code of Conduc...   \n",
       "\n",
       "                                      generated_text  \\\n",
       "0  The company prohibits discrimination and haras...   \n",
       "1  Compliance with law and firm policies for HR p...   \n",
       "\n",
       "                                           reference  \n",
       "0  The company prohibits discrimination and haras...  \n",
       "1  Compliance with law and firm policies for HR p...  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "id": "981e0b1d-b50c-47c9-aae9-4feaf5b99b27"
   },
   "outputs": [],
   "source": [
    "from ibm_aigov_facts_client import AIGovFactsClient\n",
    "\n",
    "facts_client = AIGovFactsClient(\n",
    "    api_key=CLOUD_API_KEY,\n",
    "    container_id=project_id,\n",
    "    container_type=\"project\",\n",
    "    disable_tracing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d29366f-bc1e-42dc-bdb2-16bc158ec41d"
   },
   "source": [
    "### Create Detached Prompt template\n",
    "\n",
    "Create a prompt template for a retrieval augmented generation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "id": "9d5eecf5-6446-4614-bf4c-1580beac1155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/11/26 15:31:47 INFO : ------------------------------ Detached Prompt Creation Started ------------------------------\n",
      "2025/11/26 15:31:49 INFO : The detached prompt with ID 0f1a6e3d-5f70-4349-a1f6-5b5ba0898cf8 was created successfully in container_id af45420b-7cf8-45ba-8b83-f29587e68020.\n"
     ]
    }
   ],
   "source": [
    "from ibm_aigov_facts_client import DetachedPromptTemplate, PromptTemplate\n",
    "\n",
    "detached_information = DetachedPromptTemplate(\n",
    "    prompt_id=\"detached_prompt\",\n",
    "    model_id=\"ibm/granite-4-h-small\",\n",
    "    model_provider=\"IBM\",\n",
    "    model_name=\"granite-4-h-small\",\n",
    "    model_url=\"model_url\",\n",
    "    prompt_url=\"prompt_url\",\n",
    "    prompt_additional_info={\"IBM Cloud Region\": \"us-east1\"}\n",
    ")\n",
    "\n",
    "task_id = \"retrieval_augmented_generation\"\n",
    "name = AGENTIC_RAG_LC_DEV_NAME\n",
    "description = AGENTIC_RAG_LC_DEV_NAME\n",
    "model_id = \"ibm/granite-4-h-small\"\n",
    "\n",
    "# define parameters for PromptTemplate\n",
    "prompt_variables = {\"context\": \"\", \"query\": \"\"}\n",
    "input = prompt_input\n",
    "input_prefix= \"\"\n",
    "output_prefix= \"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input=input,\n",
    "    prompt_variables=prompt_variables,\n",
    "    input_prefix=input_prefix,\n",
    "    output_prefix=output_prefix,\n",
    ")\n",
    "\n",
    "pta_details = facts_client.assets.create_detached_prompt(\n",
    "    model_id=model_id,\n",
    "    task_id=task_id,\n",
    "    name=name,\n",
    "    description=description,\n",
    "    prompt_details=prompt_template,\n",
    "    detached_information=detached_information)\n",
    "project_pta_id = pta_details.to_dict()[\"asset_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bacbe5d-fa65-4fa1-9be4-6667b8777cef"
   },
   "source": [
    "### Configure watsonx.governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "id": "93b76acb-f9ea-41fb-b44c-c1dc331ca491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.2\n"
     ]
    }
   ],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator, CloudPakForDataAuthenticator\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "authenticator = IAMAuthenticator(\n",
    "    apikey=CLOUD_API_KEY,\n",
    "    url=IAM_URL\n",
    ")\n",
    "wos_client = APIClient(\n",
    "    authenticator=authenticator,\n",
    "    service_url=SERVICE_URL,\n",
    "    service_instance_id=OPENSCALE_INSTANCE_ID\n",
    ")\n",
    "data_mart_id = wos_client.service_instance_id\n",
    "print(wos_client.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29e746cf-2148-4c3d-a44a-e6acd09f96ce"
   },
   "source": [
    "### For computing answer quality and retrieval quality metrics you are required to configure LLM As Judge.\n",
    "\n",
    "To compute metrics using LLM As Judge a generative_ai_evaluator integrated system should to be created and provided during prompt setup.\n",
    "\n",
    "#### Create a Generative AI evaluator\n",
    "The Generative AI Evaluator can be any model from watsonx.ai or a custom endpoint invoking external models\n",
    "\n",
    "Supported evaluator types\n",
    "* watsonx.ai (for connecting to watsonx.ai in local Cloud)\n",
    "* custom (for connecting to any external models)\n",
    "\n",
    "#### Integrated System parameters\n",
    "| Parameter | Description |\n",
    "|:-|:-|\n",
    "| `name` | Name for the evaluator. |\n",
    "| `description` | Description for the evaluator. |\n",
    "| `type` | The type of integrated system. Provide `generative_ai_evaluator`. |\n",
    "| `parameters` | The evaluator configuration details like `evaluator_type` and `model_id`. |\n",
    "| `credentials` | The user credentials |\n",
    "| `connection` [Optional]| The scoring endpoint details when the evaluator is of type `custom`. |\n",
    "\n",
    "As an example, an evaluator using FLAN_UL2 model from watsonx.ai instance present in the same Cloud is created below. The other models which can be used from watsonx.ai are FLAN_T5_XXL, FLAN_UL2, FLAN_T5_XL, MIXTRAL_8X7B_INSTRUCT_V01.\n",
    "For more details on the parameters and to create the other supported evaluators please refer to the link [Generative AI evaluator templates](https://github.ibm.com/aiopenscale/notebooks/wiki/Generative-AI-Evaluator-templates#for-ibm-watsonxgovernance-in-cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "id": "275e6840-0aa2-461f-af1e-da371297b57c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'019ac0ca-db03-77ff-8f0a-d0c21ffcde18'"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "gen_ai_evaluator = wos_client.integrated_systems.add(\n",
    "    name=\"RAG Metrics Evaluator\",\n",
    "    description=\"RAG Metrics Evaluator\",\n",
    "    type=\"generative_ai_evaluator\",\n",
    "    parameters={\"evaluator_type\": \"watsonx.ai\", \"model_id\": \"meta-llama/llama-3-3-70b-instruct\"},\n",
    "    credentials={\n",
    "        \"wml_location\": \"cloud\",\n",
    "        \"apikey\": CLOUD_API_KEY,\n",
    "    },\n",
    ")\n",
    "\n",
    "# get evaluator integrated system ID\n",
    "result = gen_ai_evaluator.result._to_dict()\n",
    "evaluator_id = result[\"metadata\"][\"id\"]\n",
    "evaluator_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6502e690-a0eb-49a4-b23e-f5772d68f70b"
   },
   "source": [
    "#### Generative AI monitor parameters\n",
    "\n",
    "##### Generative AI evaluator parameters\n",
    "The generative_ai_evaluator details can be provided at the global level under `generative_ai_quality.parameters` to use the same evaluator for all the Answer quality metrics(Faithfulness, Answer relevance, Answer similarity) and Retrieval quality metrics(Context relevance, Retrieval precision, Average precision, Reciprocal rank, Hit rate, Normalized Discounted Cumulative Gain).\n",
    "\n",
    "The generative ai evaluator can be specified at metric level to use different evaluators for each of the metric. The metrics under which generative_ai_evaluator parameter can be specified are faithfulness, answer_relevance, answer_similarity and retrieval_quality. The generative_ai_evaluator at the metric level takes precedence over the generative_ai_evaluator at global level\n",
    "\n",
    "| Parameter | Description | Default Value |\n",
    "|:-|:-|:-|\n",
    "| `enabled`| The flag to enable generative ai evaluator |  |\n",
    "| `evaluator_id`| The id of the generative ai evaluator integrated system. |  |\n",
    "\n",
    "##### Faithfulness, Context relevance, Answer relevance and Answer similarity parameters\n",
    "\n",
    "| Parameter | Description | Default Value |\n",
    "|:-|:-|:-|\n",
    "| `metric_prompt_template` [Optional]| The prompt template used to compute each metric values. User can override the prompt template used by watsonx.governance to compute the metric using this parameter. The prompt template should use the variables {context}, {question}, {answer}, {reference_answer} as needed and these variable values will be filled with the actual data while calling the scoring function. The prompt response should return the metric value in the range 1-10 for the respective metric and in one of the formats [\"4\", \"7 star\", \"star: 8\", \"stars: 9\"] as answer. |  |\n",
    "\n",
    "##### Unsuccessful requests parameters\n",
    "\n",
    "| Parameter | Description | Default Value |\n",
    "|:-|:-|:-|\n",
    "| `unsuccessful_phrases` [Optional]| The list of phrases to be used for comparing the model output to determine whether the request is unsuccessful or not. | `[\"i don't know\", \"i do not know\", \"i'm not sure\", \"i am not sure\", \"i'm unsure\", \"i am unsure\", \"i'm uncertain\", \"i am uncertain\", \"i'm not certain\", \"i am not certain\", \"i can't fulfill\", \"i cannot fulfill\"]` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a628b3f-21cd-4ff0-9271-97db5e84bffd"
   },
   "source": [
    "## Configure Answer Quality metrics & Retrieval Quality metrics\n",
    "<a id=\"config\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93eeb5fd-096a-41a8-a7f5-24eb65f40245"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41c693ff-2f92-47cd-882a-06cc83b3e2fb"
   },
   "source": [
    "#### Common parameters\n",
    "\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "|:-|:-|:-|:-|\n",
    "| context_columns | The list of context column names in the input data frame. |  |  |\n",
    "| question_column | the name of the question column in the input data frame. |  |  |\n",
    "| answer_column | The name of the answer column in the input data frame |  |  |\n",
    "| record_level | The flag to return the record level metrics values. Set the flag under configuration to generate record level metrics for all the metrics. Set the flag under specific metric to generate record level metrics for that metric alone. | `False` | `True`, `False` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7159495a-6ae2-4569-b588-22f74398081a"
   },
   "source": [
    "#### Faithfulness parameters\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "|:-|:-|:-|:-|\n",
    "| attributions_count [Optional]| Source attributions are computed for each sentence in the generated answer. Source attribution for a sentence is the set of sentences in the context which contributed to the LLM generating that sentence in the answer.  The attributions_count parameter specifies the number of sentences in the context which need to be identified for attributions.  E.g., if the value is set to 2, then we will find the top 2 sentences from the context as source attributions. | `3` |  |\n",
    "| ngrams [Optional]| The number of sentences to be grouped from the context when computing faithfulness score. These grouped sentences will be shown in the attributions. Having a very high value of ngrams might lead to having lower faithfulness scores due to dispersion of data and inclusion of unrelated sentences in the attributions. Having a very low value might lead to increase in metric computation time and attributions not capturing the all the aspects of the answer. | `2` |  |\n",
    "| sample_size [Optional]| The faithfulness metric is computed for a maximum of 50 LLM responses.  If you wish to compute it for a smaller number of responses, set the sample_size value to a lower number. If the number of records in the input data frame are more than the sample size, a uniform random sample will taken for computation. | `50` | Integer between 0 to 50. Max value supported is 50 |\n",
    "| record_level [Optional]| Set the flag to generate record level metrics for the specific metric. | `False` | `True`, `False` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "514eb681-aee3-42db-b9d5-43dfb0c012e0"
   },
   "source": [
    "#### Context relevance parameters\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "|:-|:-|:-|:-|\n",
    "| ngrams [Optional]| The number of sentences to be grouped from the context when computing context relevance score. Having a very high value of ngrams might lead to having lower context relevance scores due to dispersion of data and inclusion of unrelated sentences. | `5` |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9235345-55f2-4fee-81c7-0cf8620507b4"
   },
   "source": [
    "\n",
    "#### Unsuccessful requests parameters\n",
    "| Parameter | Description | Default Value |\n",
    "|:-|:-|:-|\n",
    "| unsuccessful_phrases [Optional]| The list of phrases to be used for comparing the model output to determine whether the request is unsuccessful or not. | `[\"i don't know\", \"i do not know\", \"i'm not sure\", \"i am not sure\", \"i'm unsure\", \"i am unsure\", \"i'm uncertain\", \"i am uncertain\", \"i'm not certain\", \"i am not certain\", \"i can't fulfill\", \"i cannot fulfill\"]` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7b6546b-f3cf-4264-a249-0a0bb273970f"
   },
   "source": [
    "### Configure faithfulness, answer relevance, and unsuccessful requests parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "id": "58edc161-6e5e-4034-b992-a2ee4b86082f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "This method will be deprecated in the next release and be replaced by wos_client.wos.execute_prompt_setup() method\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=============================================================================\n",
      "\n",
      " Waiting for end of adding prompt setup 0f1a6e3d-5f70-4349-a1f6-5b5ba0898cf8 \n",
      "\n",
      "=============================================================================\n",
      "\n",
      "\n",
      "\n",
      "running..\n",
      "finished\n",
      "\n",
      "---------------------------------------------------------------\n",
      " Successfully finished setting up prompt template subscription \n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt_template_asset_id': '0f1a6e3d-5f70-4349-a1f6-5b5ba0898cf8',\n",
       " 'project_id': 'af45420b-7cf8-45ba-8b83-f29587e68020',\n",
       " 'deployment_id': 'dcb0b5b8-798f-4329-926f-1adf5a435a4f',\n",
       " 'service_provider_id': '019abfc2-1795-732e-bbeb-ddbab3031834',\n",
       " 'subscription_id': '019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c',\n",
       " 'mrm_monitor_instance_id': '019ac0cb-1858-72be-a605-62b5f6f85264',\n",
       " 'start_time': '2025-11-26T15:31:53.554412Z',\n",
       " 'end_time': '2025-11-26T15:32:14.772759Z',\n",
       " 'status': {'state': 'FINISHED'}}"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_column = \"reference\"\n",
    "context_fields = [\"context\"]\n",
    "question_field = \"query\"\n",
    "operational_space_id = \"development\"\n",
    "problem_type= \"retrieval_augmented_generation\"\n",
    "input_data_type= \"unstructured_text\"\n",
    "\n",
    "monitors = {\n",
    "    \"generative_ai_quality\": {\n",
    "        \"parameters\": {\n",
    "            \"generative_ai_evaluator\": { # global LLM as judge configuration\n",
    "               \"enabled\": True,\n",
    "               \"evaluator_id\": evaluator_id,\n",
    "            },\n",
    "            \"min_sample_size\": 2,\n",
    "            \"metrics_configuration\": {\n",
    "                \"faithfulness\": {\n",
    "                    # \"metric_prompt_template\": \"\", # adding custom template\n",
    "                    # Uncomment generative_ai_evaluator to use a different evaluator for this metric.\n",
    "                    # Takes higher precedence than the generative_ai_evaluator specified at global level.\n",
    "                    # \"generative_ai_evaluator\": {  # metric specific LLM as judge configuration\n",
    "                    #     \"enabled\": True,\n",
    "                    #     \"evaluator_id\": evaluator_id,\n",
    "                    # },\n",
    "                },\n",
    "                \"answer_relevance\": {\n",
    "                    # \"metric_prompt_template\": \"\", # adding custom template\n",
    "                    # Uncomment generative_ai_evaluator to use a different evaluator for this metric\n",
    "                    # Takes higher precedence than the generative_ai_evaluator specified at global level.\n",
    "                    # \"generative_ai_evaluator\": {  # metric specific LLM as judge configuration\n",
    "                    #     \"enabled\": True,\n",
    "                    #     \"evaluator_id\": evaluator_id,\n",
    "                    # },\n",
    "                },\n",
    "                \"rouge_score\": {},\n",
    "                \"exact_match\": {},\n",
    "                \"bleu\": {},\n",
    "                \"unsuccessful_requests\": {\n",
    "                    # \"unsuccessful_phrases\": []\n",
    "                },\n",
    "                \"hap_input_score\": {},\n",
    "                \"hap_score\": {},\n",
    "                \"pii\": {},\n",
    "                \"pii_input\": {},\n",
    "                \"retrieval_quality\": {\n",
    "                    # Uncomment generative_ai_evaluator to use a different evaluator for this metric\n",
    "                    # Takes higher precedence than the generative_ai_evaluator specified at global level.\n",
    "                    # \"generative_ai_evaluator\": {  # metric specific LLM as judge configuration\n",
    "                    #     \"enabled\": True,\n",
    "                    #     \"evaluator_id\": evaluator_id,\n",
    "                    # },\n",
    "                    # The metrics computed for retrieval quality are context_relevance, retrieval_precision, average_precision, reciprocal_rank, hit_rate, normalized_discounted_cumulative_gain\n",
    "                    # \"context_relevance\": {\n",
    "                    #     \"metric_prompt_template\": \"\", # adding custom template\n",
    "                    # }\n",
    "                },\n",
    "                # Answer similarity metric is supported only when LLM as judge is configured. Uncomment only when using LLM as judge.\n",
    "                \"answer_similarity\": {\n",
    "                    # \"metric_prompt_template\": \"\", # adding custom template\n",
    "                    # Uncomment generative_ai_evaluator to use a different evaluator for this metric\n",
    "                    # Takes higher precedence than the generative_ai_evaluator specified at global level.\n",
    "                    # \"generative_ai_evaluator\": {  # metric specific LLM as judge configuration\n",
    "                    #     \"enabled\": True,\n",
    "                    #     \"evaluator_id\": evaluator_id,\n",
    "                    # },\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = wos_client.monitor_instances.mrm.execute_prompt_setup(\n",
    "    prompt_template_asset_id=project_pta_id, \n",
    "    project_id=project_id,\n",
    "    label_column=label_column,\n",
    "    context_fields = context_fields,     \n",
    "    question_field = question_field,     \n",
    "    operational_space_id=operational_space_id, \n",
    "    problem_type=problem_type,\n",
    "    input_data_type=input_data_type, \n",
    "    supporting_monitors=monitors, \n",
    "    background_mode=False\n",
    ")\n",
    "\n",
    "result = response.result\n",
    "result.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c129e9d5-52b9-4c78-8385-ace144617eb9"
   },
   "source": [
    "With the following cell, you can read the prompt setup task and check its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "id": "4d903cbc-64d3-4be8-bd6d-75ed808aa276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "This method will be deprecated in the next release and be replaced by wos_client.wos.get_prompt_setup() method\n",
      "=================================================================\n",
      "Finished prompt setup. The response is {'prompt_template_asset_id': '0f1a6e3d-5f70-4349-a1f6-5b5ba0898cf8', 'project_id': 'af45420b-7cf8-45ba-8b83-f29587e68020', 'deployment_id': 'dcb0b5b8-798f-4329-926f-1adf5a435a4f', 'service_provider_id': '019abfc2-1795-732e-bbeb-ddbab3031834', 'subscription_id': '019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c', 'mrm_monitor_instance_id': '019ac0cb-1858-72be-a605-62b5f6f85264', 'start_time': '2025-11-26T15:31:53.554412Z', 'end_time': '2025-11-26T15:32:14.772759Z', 'status': {'state': 'FINISHED'}}\n"
     ]
    }
   ],
   "source": [
    "response = wos_client.monitor_instances.mrm.get_prompt_setup(\n",
    "    prompt_template_asset_id=project_pta_id,\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "result = response.result\n",
    "result_json = result.to_dict()\n",
    "\n",
    "if result_json[\"status\"][\"state\"] == \"FINISHED\":\n",
    "    print(\"Finished prompt setup. The response is {}\".format(result_json))\n",
    "else:\n",
    "    print(\"Prompt setup failed. The response is {}\".format(result_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "id": "b2d49409-24cf-42c1-9982-f3c474b829a3"
   },
   "outputs": [],
   "source": [
    "subscription_id = result_json[\"subscription_id\"]\n",
    "mrm_monitor_instance_id = result_json[\"mrm_monitor_instance_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56709bff-f7d6-4d57-aac6-836bedb32599"
   },
   "source": [
    "### Show all monitor instances in the development subscription\n",
    "The following cell lists the monitors present in the development subscription, along with their respective statuses and other details. Please wait for all the monitors to be in an active state before proceeding further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "id": "ab997dfb-c8a9-45b9-b977-ec7fc860702f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>Monitor instances</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>data_mart_id</th><th style='border: 1px solid #dddddd'>status</th><th style='border: 1px solid #dddddd'>target_id</th><th style='border: 1px solid #dddddd'>target_type</th><th style='border: 1px solid #dddddd'>monitor_definition_id</th><th style='border: 1px solid #dddddd'>created_at</th><th style='border: 1px solid #dddddd'>id</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>4ad03e71-3c45-4f42-9a29-c4d2a0425b10</td><td style='border: 1px solid #dddddd'>active</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>2025-11-26 15:32:05.561000+00:00</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td></tr><tr><td style='border: 1px solid #dddddd'>4ad03e71-3c45-4f42-9a29-c4d2a0425b10</td><td style='border: 1px solid #dddddd'>active</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>model_health</td><td style='border: 1px solid #dddddd'>2025-11-26 15:32:06.560000+00:00</td><td style='border: 1px solid #dddddd'>019ac0cb-152d-7505-8efd-f3b31d5a323a</td></tr><tr><td style='border: 1px solid #dddddd'>4ad03e71-3c45-4f42-9a29-c4d2a0425b10</td><td style='border: 1px solid #dddddd'>active</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>mrm</td><td style='border: 1px solid #dddddd'>2025-11-26 15:32:07.392000+00:00</td><td style='border: 1px solid #dddddd'>019ac0cb-1858-72be-a605-62b5f6f85264</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wos_client.monitor_instances.show(target_target_id=subscription_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c8768ff-b8eb-4d33-9996-941d70343a47"
   },
   "source": [
    "### Risk evaluations for the PTA subscription - Evaluate the prompt template subscription\n",
    "\n",
    "For risk assessment of a `development`-type subscription, you must have an evaluation dataset. The risk assessment function takes the evaluation dataset path as a parameter when evaluating the configured metrics. If there is a discrepancy between the feature columns in the subscription and the column names in the uploading `.CSV` file, you have the option to supply a mapping JSON file to associate the `.CSV` column names with the feature column names in the subscription.\n",
    "\n",
    "**Note**: If you are running this notebook from Watson Studio, you may first need to upload your test data to Watson Studio, then run the code snippet below to download the feedback data file from the project to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "id": "51072101-0163-4d50-9f99-de781a64cad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=================================================================================\n",
      "\n",
      " Waiting for risk evaluation of MRM monitor 019ac0cb-1858-72be-a605-62b5f6f85264 \n",
      "\n",
      "=================================================================================\n",
      "\n",
      "\n",
      "\n",
      "upload_in_progress.\n",
      "running.....\n",
      "finished\n",
      "\n",
      "---------------------------------------\n",
      " Successfully finished evaluating risk \n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_set_name = \"data\"\n",
    "content_type = \"multipart/form-data\"\n",
    "body = {}\n",
    "\n",
    "# Preparing the test data, removing extra columns\n",
    "cols_to_remove = [\"uid\", \"doc\", \"title\", \"id\"]\n",
    "for col in cols_to_remove:\n",
    "    if col in llm_data:\n",
    "        del llm_data[col]\n",
    "llm_data.to_csv(test_data_path, index=False)\n",
    "\n",
    "response  = wos_client.monitor_instances.mrm.evaluate_risk(\n",
    "    monitor_instance_id=mrm_monitor_instance_id,\n",
    "    test_data_set_name=test_data_set_name, \n",
    "    test_data_path=test_data_path,\n",
    "    content_type=content_type,\n",
    "    body=body,\n",
    "    project_id=project_id,\n",
    "    includes_model_output=True,\n",
    "    background_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "id": "6aa46ced-2a61-4c65-8a1e-99a805d3093f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'id': 'c7d8969e-c3c5-4c13-b42b-5670ae2ad6f1',\n",
       "  'created_at': '2025-11-26T15:32:33.499Z',\n",
       "  'created_by': 'iam-ServiceId-b317a8da-d926-496e-b0ca-6bcc57f556ae'},\n",
       " 'entity': {'triggered_by': 'user',\n",
       "  'parameters': {'evaluation_start_time': '2025-11-26T15:32:18.411887Z',\n",
       "   'evaluator_user_key': 'd6fd8b44-fea0-4046-9898-934e83ec6d24',\n",
       "   'is_auto_evaluated': False,\n",
       "   'measurement_id': '019ac0cb-80b2-797a-8fd8-eac9dc52cd3d',\n",
       "   'monitors_run_status': [{'monitor_id': 'generative_ai_quality',\n",
       "     'status': {'state': 'finished'}},\n",
       "    {'monitor_id': 'model_health', 'status': {'state': 'finished'}}],\n",
       "   'project_id': 'af45420b-7cf8-45ba-8b83-f29587e68020',\n",
       "   'prompt_template_asset_id': '0f1a6e3d-5f70-4349-a1f6-5b5ba0898cf8',\n",
       "   'user_iam_id': 'IBMid-1100008S88',\n",
       "   'wos_created_deployment_id': 'dcb0b5b8-798f-4329-926f-1adf5a435a4f',\n",
       "   'publish_metrics': 'false',\n",
       "   'evaluation_tests': ['drift_v2',\n",
       "    'fairness',\n",
       "    'generative_ai_quality',\n",
       "    'generative_ai_security',\n",
       "    'model_health',\n",
       "    'quality']},\n",
       "  'status': {'state': 'finished',\n",
       "   'queued_at': '2025-11-26T15:32:33.481000Z',\n",
       "   'started_at': '2025-11-26T15:32:34.326000Z',\n",
       "   'updated_at': '2025-11-26T15:33:23.564000Z',\n",
       "   'completed_at': '2025-11-26T15:33:22.015000Z',\n",
       "   'message': 'Mrm evaluation complete.',\n",
       "   'operators': []}}}"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response  = wos_client.monitor_instances.mrm.get_risk_evaluation(mrm_monitor_instance_id, project_id=project_id)\n",
    "response.result.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29ac7313-a9c6-4699-8a2a-07bfece896da"
   },
   "source": [
    "### Display the Model Risk metrics.\n",
    "\n",
    "Having calculated the measurements for the Foundation Model subscription, the Model Risk metrics generated for this subscription are available for your review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "id": "082b49fa-6664-4d3d-99cc-0208a9e01d3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>019ac0cb-1858-72be-a605-62b5f6f85264 Monitor Runs Metrics from: 2025-11-19 15:33:28.088383  till: 2025-11-26 15:33:28.088395</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>ts</th><th style='border: 1px solid #dddddd'>id</th><th style='border: 1px solid #dddddd'>measurement_id</th><th style='border: 1px solid #dddddd'>value</th><th style='border: 1px solid #dddddd'>lower_limit</th><th style='border: 1px solid #dddddd'>upper_limit</th><th style='border: 1px solid #dddddd'>tags</th><th style='border: 1px solid #dddddd'>monitor_definition_id</th><th style='border: 1px solid #dddddd'>monitor_instance_id</th><th style='border: 1px solid #dddddd'>run_id</th><th style='border: 1px solid #dddddd'>target_type</th><th style='border: 1px solid #dddddd'>target_id</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2025-11-26 15:32:33.586000+00:00</td><td style='border: 1px solid #dddddd'>tests_passed</td><td style='border: 1px solid #dddddd'>019ac0cb-80b2-797a-8fd8-eac9dc52cd3d</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['test_data_set_name:data']</td><td style='border: 1px solid #dddddd'>mrm</td><td style='border: 1px solid #dddddd'>019ac0cb-1858-72be-a605-62b5f6f85264</td><td style='border: 1px solid #dddddd'>c7d8969e-c3c5-4c13-b42b-5670ae2ad6f1</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:32:33.586000+00:00</td><td style='border: 1px solid #dddddd'>tests_run</td><td style='border: 1px solid #dddddd'>019ac0cb-80b2-797a-8fd8-eac9dc52cd3d</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['test_data_set_name:data']</td><td style='border: 1px solid #dddddd'>mrm</td><td style='border: 1px solid #dddddd'>019ac0cb-1858-72be-a605-62b5f6f85264</td><td style='border: 1px solid #dddddd'>c7d8969e-c3c5-4c13-b42b-5670ae2ad6f1</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:32:33.586000+00:00</td><td style='border: 1px solid #dddddd'>tests_skipped</td><td style='border: 1px solid #dddddd'>019ac0cb-80b2-797a-8fd8-eac9dc52cd3d</td><td style='border: 1px solid #dddddd'>4.0</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['test_data_set_name:data']</td><td style='border: 1px solid #dddddd'>mrm</td><td style='border: 1px solid #dddddd'>019ac0cb-1858-72be-a605-62b5f6f85264</td><td style='border: 1px solid #dddddd'>c7d8969e-c3c5-4c13-b42b-5670ae2ad6f1</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:32:33.586000+00:00</td><td style='border: 1px solid #dddddd'>tests_failed</td><td style='border: 1px solid #dddddd'>019ac0cb-80b2-797a-8fd8-eac9dc52cd3d</td><td style='border: 1px solid #dddddd'>0.0</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['test_data_set_name:data']</td><td style='border: 1px solid #dddddd'>mrm</td><td style='border: 1px solid #dddddd'>019ac0cb-1858-72be-a605-62b5f6f85264</td><td style='border: 1px solid #dddddd'>c7d8969e-c3c5-4c13-b42b-5670ae2ad6f1</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=mrm_monitor_instance_id, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "id": "42aea40b-2981-4a53-8610-421a5a98cc1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'019ac0cb-0f60-79c3-8bb0-316e2fd0c470'"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor_definition_id = \"generative_ai_quality\"\n",
    "result = wos_client.monitor_instances.list(\n",
    "    data_mart_id=data_mart_id,\n",
    "    monitor_definition_id=monitor_definition_id,\n",
    "    target_target_id=subscription_id,\n",
    "    project_id=project_id\n",
    ").result\n",
    "result_json = result._to_dict()\n",
    "genaiquality_monitor_id = result_json[\"monitor_instances\"][0][\"metadata\"][\"id\"]\n",
    "genaiquality_monitor_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d402b72-4a53-4d17-a94c-d590a45ecc50"
   },
   "source": [
    "## Display the Generative AI quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "id": "36e57b27-4387-4313-baee-40ebcb90bb1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>019ac0cb-0f60-79c3-8bb0-316e2fd0c470 Monitor Runs Metrics from: 2025-11-19 15:33:30.407022  till: 2025-11-26 15:33:30.407035</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>ts</th><th style='border: 1px solid #dddddd'>id</th><th style='border: 1px solid #dddddd'>measurement_id</th><th style='border: 1px solid #dddddd'>value</th><th style='border: 1px solid #dddddd'>lower_limit</th><th style='border: 1px solid #dddddd'>upper_limit</th><th style='border: 1px solid #dddddd'>tags</th><th style='border: 1px solid #dddddd'>monitor_definition_id</th><th style='border: 1px solid #dddddd'>monitor_instance_id</th><th style='border: 1px solid #dddddd'>run_id</th><th style='border: 1px solid #dddddd'>target_type</th><th style='border: 1px solid #dddddd'>target_id</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>hap_input_score</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>0.0</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>0.0</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>rouge2</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>0.8</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>faithfulness</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>0.7</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>average_precision</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>0.7</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>records_processed</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>2.0</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>hit_rate</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>0.7</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>rougelsum</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>0.8</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>answer_relevance</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>0.7</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>hap_score</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>0.0</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>0.0</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-26 15:33:11.777607+00:00</td><td style='border: 1px solid #dddddd'>reciprocal_rank</td><td style='border: 1px solid #dddddd'>019ac0cc-15e1-793c-8c52-d1479ab036c2</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>0.7</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['computed_on:feedback', 'field_type:subscription', 'aggregation_type:mean']</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>019ac0cb-0f60-79c3-8bb0-316e2fd0c470</td><td style='border: 1px solid #dddddd'>ea9fa97e-6dfb-4c7b-a65a-0a68b4f608ab</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>019ac0ca-f7f3-7c9e-a9af-5b784c7abd2c</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: First 10 records were displayed.\n"
     ]
    }
   ],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=genaiquality_monitor_id, project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32dc6e4e-af89-4130-a24e-61b450769379"
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have completed this notebook. You can now navigate to the prompt template asset in your watsonx.governance project / space and click on the `Evaluate` tab to visualize the results in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48f3d37b-0fe7-489c-918e-af363d7c9ccc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
